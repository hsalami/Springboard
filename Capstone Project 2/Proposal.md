
## Proposal for Capstone Project 2

**Title**:  Predicting restaurants’ violations of Allegheny County (Pittsburgh city) 

**Problem**: Local public health departments regularly inspect food facilities to ensure they’re following safe food handling measures. These inspections check if proper procedures are being taken to protect food from contaminations, and that there is no health risk on consumers (such as food poisoning and spread of Salmonella). In Allegheny County, these inspections are mandatory, done annually and sometimes twice a year, and they happen unannounced. The inspections of this county aim to uncover any critical violations in food handling such as improper cooking practices, holding food at the wrong temperature or inadequate hand washing facilities, and non-critical such as insufficient ventilation or inadequate lighting. If violations are found during the inspection, a re-inspection is scheduled. Failure to fix the violations may result in administrative intervention, civil penalties (fines), or facility closure, depending on the severity and frequency of the violations. However, due to shortage in staff, many restaurants in Allegheny County are not recently being inspected, which means that some violations are going unchecked. According to this article, numerous prominent restaurants and kitchens in the Downtown region haven’t been inspected since 2017. This is why it could be helpful for the county to know how to prioritize their inspections and to first check restaurants where violations are more likely to occur. In this project, we propose a model that combines Yelp reviews with the history of inspections to predict possible violations of Allegheny County’s restaurants.

**Who might care?** The model can help Allegheny County in their inspections’ efforts.  It can improve the inspection process by identifying which restaurants to target first, reducing the number of violations missed and detecting any risks earlier. The model can also help consumers getting better views about the food handling practices of any restaurant they plan to visit.

**Data**: The dataset available [here](https://data.wprdc.org/dataset/allegheny-county-restaurant-food-facility-inspection-violations) contains the restaurants’ violations collected from January 2016 to present. This dataset is updated monthly and currently has around 238,859 entries with the following fields: 
facility name, business start date, description of the facility, location, inspection date and times, violation category, rating (V indicates violation), low (low risk violation), medium (medium risk violation), high (high risk violation) and a link to the full inspection report. 
This dataset can be combined with the dataset provided by [YELP](https://www.yelp.com/dataset/challenge), in order to see if the reviews helps in predicting the violation of a restaurant. The YELP dataset contains business data including location, attributes, and categories, as well as full review texts, tips, and user information.

**Modeling Approach**: Each violation is classified into low, medium or high risk violation. During the same inspection, the number of each type of violations is reported. Therefore, we can have two options for the modeling objective: to estimate the number of each type of violations of an inspection or to classify the inspection result into class 1 (if at least a high or medium risk violations happened) or class 0 (otherwise). Most of the work will be focused on creating the relevant features. For each restaurant, we will collect their static information: category of the restaurant, cuisine, location, business start date, opening hours, range of dollars. Next, we will have information related to the inspection event (inspector, date of inspection, result).  We will then extract information from yelp that were available before the inspection event. This information can include the mean of stars given by the reviewers, numbers of reviews, and the texts of reviews. To analyze the texts of reviews, we will implement techniques from NLP (like bag of words, sentiment analysis, topic modelling) to extract relevant words or phrases. Once we have the features ready for each inspection, we will start with the modeling steps, which consists on splitting the data into training and testing sets, training different models using the training set, selecting a final model and then testing the final model using the testing set. The performance will be measured depending on the modeling objective.  

**Deliverables**: Here are the deliverables of the project:
- Codes detailing the steps done to analyze the data;
- Report on the capstone project explaining the problem, our approach, and our findings;
- Slide deck for the project.
