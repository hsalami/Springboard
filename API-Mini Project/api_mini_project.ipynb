{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API MINI-Project\n",
    "\n",
    "In this project, we focus on equities data from the Frankfurt Stock Exchange (FSE), available from Quandl API. More specifically, we address some questions related to the stock prices of a company called [Carl Zeiss Meditec](https://www.zeiss.com/meditec/int/home.html), which manufactures tools for eye examinations, as well as medical lasers for laser eye surgery. The company is listed under the stock ticker AFX_X.\n",
    "\n",
    "To send requests to Quandl API and get access to the data, we first register on [Quandl website](http://www.quandl.com) and obtain an API key that we store as a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the API key as a string \n",
    "API_KEY = '...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Glimpse into the Data\n",
    "\n",
    "Before we address the tasks of this mini-project, we pull out a sample of 2 days from the data in order to explore the structure of the data returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, import the relevant modules\n",
    "import requests\n",
    "\n",
    "# Now, call the Quandl API and pull out a small sample of two days to get a glimpse into the returned JSON structure \n",
    "url='https://www.quandl.com/api/v3/datasets/FSE/AFX_X/data.json?limit=2&api_key='+API_KEY\n",
    "r=requests.get(url)\n",
    "json_data=r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_data': {'limit': 2, 'transform': None, 'column_index': None, 'column_names': ['Date', 'Open', 'High', 'Low', 'Close', 'Change', 'Traded Volume', 'Turnover', 'Last Price of the Day', 'Daily Traded Units', 'Daily Turnover'], 'start_date': '2000-06-07', 'end_date': '2019-10-07', 'frequency': 'daily', 'data': [['2019-10-07', 108.5, 110.3, 107.5, 108.8, None, 97154.0, 10561664.0, None, None, None], ['2019-10-04', 105.0, 109.5, 104.4, 108.2, None, 198283.0, 21355196.0, None, None, None]], 'collapse': None, 'order': None}}\n"
     ]
    }
   ],
   "source": [
    "# Inspect the JSON structure of the object you created\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we can find the column names as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column names are as follows:\n",
      "\n",
      "['Date', 'Open', 'High', 'Low', 'Close', 'Change', 'Traded Volume', 'Turnover', 'Last Price of the Day', 'Daily Traded Units', 'Daily Turnover']\n"
     ]
    }
   ],
   "source": [
    "print('The column names are as follows:\\n')\n",
    "print(json_data['dataset_data']['column_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, the data can be retrieved as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data is given as a list of lists:\n",
      "\n",
      "[['2019-10-07', 108.5, 110.3, 107.5, 108.8, None, 97154.0, 10561664.0, None, None, None], ['2019-10-04', 105.0, 109.5, 104.4, 108.2, None, 198283.0, 21355196.0, None, None, None]]\n"
     ]
    }
   ],
   "source": [
    "print('The data is given as a list of lists:\\n')\n",
    "print(json_data['dataset_data']['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Tasks\n",
    "\n",
    "We now consider the following tasks:\n",
    "\n",
    "1. Collect data from the Franfurt Stock Exchange, for the ticker AFX_X, for the whole year 2017 (keep in mind that the date format is YYYY-MM-DD).\n",
    "2. Convert the returned JSON object into a Python dictionary.\n",
    "3. Calculate what the highest and lowest opening prices were for the stock in this period.\n",
    "4. What was the largest change in any one day (based on High and Low price)?\n",
    "5. What was the largest change between any two days (based on Closing Price)?\n",
    "6. What was the average daily trading volume during this year?\n",
    "7. (Optional) What was the median trading volume during this year. (Note: you may need to implement your own function for calculating the median.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1**: We first collect the data for the whole year 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Collect data from the Franfurt Stock Exchange, for the ticker AFX_X, for the whole year 2017\n",
    "url='https://www.quandl.com/api/v3/datasets/FSE/AFX_X/data.json?start_date=2017-01-01&end_date=2017-12-31&api_key='+API_KEY\n",
    "r=requests.get(url)\n",
    "json_data=r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2**: Using defaultdict from the collections library, we convert the JSON object into a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Convert the returned JSON object into a Python dictionary\n",
    "\n",
    "# import defaultdict\n",
    "from collections import defaultdict\n",
    "\n",
    "# create empty dictionary\n",
    "data=defaultdict(list)\n",
    "\n",
    "# find the column names\n",
    "colnames=json_data['dataset_data']['column_names']\n",
    "\n",
    "# retrieve the data stored as list of lists\n",
    "datalists=json_data['dataset_data']['data']\n",
    "\n",
    "# loop over each list and store it in the dictionary 'data' under the right key\n",
    "for datalist in datalists:\n",
    "    for key,value in zip(colnames,datalist):\n",
    "        data[key].append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3**: We now find the highest and lowest opening prices for the stock for the year of 2017. The opening prices are paired with the key 'Open' in the data dictionary. Since some of the opening prices are stored as None, we first remove them and then find the maximum and minimum values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest opening price was: 53.11\n",
      "The lowest opening price was: 34.0\n"
     ]
    }
   ],
   "source": [
    "# 3. Calculate what the highest and lowest opening prices were for the stock in this period\n",
    "\n",
    "# remove the None values and then find the maximum and minimum values of opening prices\n",
    "OpenPrices=list(filter(None,data['Open']))\n",
    "highest=max(OpenPrices)\n",
    "lowest=min(OpenPrices)\n",
    "\n",
    "print('The highest opening price was:',highest)\n",
    "print('The lowest opening price was:',lowest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4**: We here find the largest change in any one day (based on High and Low price). The highest price in any given day is given under the key 'High' and the lowest price per day is given under the key 'Low'. To find the largest change in any given day, we subtract the lowest prices from the highest prices on each day and then find the largest difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest change in any one day was 2.8100000000000023\n"
     ]
    }
   ],
   "source": [
    "# 4. What was the largest change in any one day (based on High and Low price)?\n",
    "\n",
    "# subtract the entries of data['Low'] from the entries of data['High'] and then find the maximum change\n",
    "max_change=max([h-l for h,l in zip(data['High'],data['Low'])])\n",
    "\n",
    "print('The largest change in any one day was', max_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5**: We here find the largest change between any two days based on Closing Price. To get the closing prices of each day, we use the data under the key 'Close'. We then subtract the values of each two consecutive days and then find the maximum absolute change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest change between any two days was 2.559999999999995\n"
     ]
    }
   ],
   "source": [
    "# 5. What was the largest change between any two days (based on Closing Price)?\n",
    "\n",
    "# data['Close'] corresponds to closing prices from '2017-12-29' to '2017-01-02'\n",
    "\n",
    "# data['Close'][:-1]: has the closing prices from '2017-12-29' to '2017-01-03'\n",
    "# data['Close'][1:]: has the closing prices from '2017-12-28' to '2017-01-02'\n",
    "# by subtracting the above two slices, we obtain the change in closing prices between any two days\n",
    "\n",
    "max_change_2=max([abs(day2-day1) for day2,day1 in zip(data['Close'][:-1],data['Close'][1:])])\n",
    "\n",
    "print('The largest change between any two days was', max_change_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6**: We here compute the average daily trading volume during this year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average daily trading volume was 89124.33725490196\n"
     ]
    }
   ],
   "source": [
    "# 6. What was the average daily trading volume during this year?\n",
    "\n",
    "avg_volume=sum(data['Traded Volume'])/len(data['Traded Volume'])\n",
    "\n",
    "print('The average daily trading volume was',avg_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 7**: We here find the median trading volume. We first sort the trading volumes and since the length of the data is odd (255), the median is the middle value in the sorted volume data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median trading volume was  76286.0\n"
     ]
    }
   ],
   "source": [
    "# 7. What was the median trading volume during this year?\n",
    "\n",
    "# sort the traded volume\n",
    "volume_sorted=sorted(data['Traded Volume'])\n",
    "\n",
    "# find the index of the middle value (the length of the data is odd)\n",
    "mid_index=len(volume_sorted)//2\n",
    "\n",
    "# median is the middle value\n",
    "median=volume_sorted[mid_index]\n",
    "\n",
    "print('The median trading volume was ',median )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
